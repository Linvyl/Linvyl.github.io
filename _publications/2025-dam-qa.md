---
title: "Describe Anything Model for Visual Question Answering on Text-rich Images"
collection: publications
category: conferences
date: 2025-01-02
permalink: /publication/2025-iccv-dam-qa

authors: >
  <strong>Yen-Linh Vu*</strong>, Dinh-Thang Duong*,
  Truong-Binh Duong, Anh-Khoi Nguyen, Thanh-Huy Nguyen,
  Le Thien Phuc Nguyen, Jianhua Xing, Xingjian Li,
  Tianyang Wang, Ulas Bagci, Min Xu

venue: "ICCV Workshops (VisionDocs)"
year: 2025

paperurl: https://openaccess.thecvf.com/content/ICCV2025W/VisionDocs/papers/Vu_Describe_Anything_Model_for_Visual_Question_Answering_on_Text-rich_Images_ICCVW_2025_paper.pdf
codeurl: https://github.com/Linvyl/DAM-QA

note: "ICCVW 2025"
---

**Abstract.**  
We introduce the Describe Anything Model (DAM), a vision–language framework for visual question answering on text-rich images. DAM integrates document understanding, OCR-aware representations, and multimodal reasoning to improve robustness on complex visual–textual inputs.
